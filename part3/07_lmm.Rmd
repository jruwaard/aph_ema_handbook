# Mixed Modeling {#lmm}

```{r setdigits, include = FALSE}
options(digits = 3)
```

EMA data are timeseries that are characterised by complex correlational structures, irregular sampling intervals, missing data, and substantive individual differences. Mixed models are well-suited to deal with these aspects. For this reason, they are often adopted in the analysis of EMA data. This chapter provides a brief explanation of the mixed model analysis of EMA data. It shows how mixed models can be run in R, and how the output of these analyses can be interpreted.

## The Mixed Model

Mixed modeling can be understood as a regression technique in which in separate regression functions are estimated for each cluster in the data set. In EMA data, these clusters are defined by the participants. Data from the same participant are expected to be correlated, and one way to honour this correlation is to conceptualise a separate regression for each participant. This idea, in the most simple regression model, can be expressed as: 

\begin{equation} 
  Y_{ij} = intercept_{i} + \epsilon_{ij} 
\end{equation} 

This models the expected value of the jth measurement of participant i as the mean of all measurements of participant i, plus error. It defines a set of regression functions - one for each participant. The regression functions are, however, not independent:

\begin{equation} 
  intercept_{i} = intercept_{g} + intercept_{i} 
\end{equation} 

This equation divides the intercepts of the individual participant regression functions into two parts: 1) the intercept of the group (the mean intercept of all regression functions), and 2) a participant-specific component (i.e., the difference between the intercept of the participant and the mean intercept of the group). 

The group intercept is called the 'fixed' effect. If we would gather more data from the sampled population, we would expect to find approximately the same group intercept. 

The participant-specific intercept is known as the 'random' effect. If we sample new data, we would not expect the individual intercepts to be the same. Rather, we would expect a similar *variance* of the participant-specific intercepts around the group intercept. This "mixing" of fixed and random effects is what gives mixed modeling its name.

The key to mixed models is to understand that it involves the estimation of fixed effects (a single value), random effects (systematic variance) and error (residual variance).

## Simulating example data

Suppose you want to determine the degree to which people with depression differ in their mean response to an EMA mood item. For this, you invite 100 people to rate their mood, three times per day, for one week.

For illustrative purposes, let's use the 'sim_ema' function from package 'emaph' to simulate data in which the relevant model parameters are known. We set the mean mood (intercept_g) to 5, the variance around this mean - var(intercept_i) - to .5., and the average variance around these means within participants - the error - to .2.

```{r cs7a_}
# code snippet 7.1: simulating ema data
library(emaph)
plan <- sample_plan(n_participants = 100, 
                    n_days = 7,
                    times = c("10:00-11:00", 
                              "13:00-14:00", 
                              "16:00-18:00"))

d1 <- sim_ema(plan, 
              mm_par = list(fixed  = c(intercept = 5),
                            random = c(intercept = 1),
                            phi = .5,
                            error = .5),
              lim = c(0, 10))
```

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta. Vestibulum hendrerit tempus condimentum.

```{r fig7a, out.width = "100%", fig.asp = .5, echo = FALSE, warning = FALSE, message = FALSE}
library(ggplot2)
ggplot(subset(d1, id %in% unique(d1$id)[1:6]), 
       aes(x = time, y = Y, group = id)) + 
  geom_line() + ylim(c(0, 10)) + 
  facet_wrap(~id) + theme_classic()
```

## Fitting a mixed model in R

Now, let's use R to fit a mixed model to the data, to see whether it our simulation parameters are detected. For this, we will use the 'lme' function, from package 'nlme':

```{r cs7a}
# code snippet 7.1: fitting a mixed model with lme
library(nlme)
fm <- lme(Y ~ 1, random = ~ 1 | id, 
          data = d1)
```

We can now extract the fixed effects regression coefficients table. The estimated intercept should be close to 5: 

```{r cs7b}
# code snippet 7.2: fitted fixed effects
summary(fm)$tTable
```

Random effects and residual variance are shown by the 'VarCorr' function. The random intercept variance should be close to .5 and the residual error variance should be close to .2:

```{r cs7c}
# code snippet 7.3: fitted random effects
VarCorr(fm)
```

By plotting the predicted values, it becomes clear how the model 'thinks': it predicts a series of straight lines, one for each participant.

```{r fig7b, out.width = "100%", fig.asp = 0.4}
d1$predY <- predict(fm)
```


```{r echo = FALSE}
ggplot(d1, aes(x = time, y = predY, group = id)) + 
  geom_line(alpha = .1, size = .6) + 
  geom_smooth(aes(group = NULL), method = "lm", color = "red") + 
  coord_cartesian(ylim = c(0, 10)) + theme_classic()
```

## The intra-class correlation

The above reasoning does not immediately answer the question to what degree people with depression differ in their mean response to the EMA mood item. One way to quantify this, is to calculate the intra-class correlation, which is defined as the ratio between the random intercept variance and the total variance (i.e., the intercept variance and the residual variance): 

```{r cs7d}
# code snippet 7.4: intraclass correlation
vc <- VarCorr(fm)
intercept_var <- as.numeric(vc[1]) 
residual_var <- as.numeric(vc[2]) 

round(intercept_var / (intercept_var + residual_var), 2)
```
From this, we learn that 66% of the total variance in the dataset can be attributed to differences between individuals. 

## Adding time as a predictor

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta. Vestibulum hendrerit tempus condimentum. Donec a mollis
sem.

```{r fig7e, out.width = "100%", fig.asp = .75, warning = FALSE, message = FALSE}
d2 <- sim_ema(plan, 
              mm_par = list(fixed  = c(intercept = 5, time = 0.5),
                            random = c(intercept = 1, time = 0.05),
                            phi = .5,
                            error = .5),
              lim = c(0, 10))

ggplot(subset(d2, id %in% unique(d2$id)[1:9]), 
       aes(x = time, y = Y, group = id)) + 
  geom_line() + ylim(c(0, 10)) + 
  facet_wrap(~id) + theme_classic()
```

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta. Vestibulum hendrerit tempus condimentum. Donec a mollis
sem. Aenean lectus nunc, bibendum ut orci vel, tristique pellentesque arcu.
Vestibulum id laoreet neque. Phasellus at ex velit. Vestibulum scelerisque nulla
ut massa tempor, ac dapibus dui viverra.

```{r cs7f}
# code snippet 7.6: a mixed model, with a random slope
library(nlme)
fm <- lme(Y ~ 1 + time, random = ~ 1 + time | id, 
          data = d2)
summary(fm)$tTable
```

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta.

```{r cs7g}
# code snippet 7.7: extracting random effects
VarCorr(fm)
```

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta.

```{r fig7f, out.width = "100%", fig.asp = 0.4}
d2$predY <- predict(fm)

ggplot(d2, aes(x = time, y = predY, group = id)) + 
  geom_line(alpha = .1, size = .6) + 
  geom_smooth(aes(group = NULL), method = "lm", color = "red") + 
  coord_cartesian(ylim = c(0, 10)) + theme_classic()
```

## Two groups

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta. Vestibulum hendrerit tempus condimentum. Donec a mollis
sem. Aenean lectus nunc, bibendum ut orci vel, tristique pellentesque arcu.
Vestibulum id laoreet neque. Phasellus at ex velit. Vestibulum scelerisque nulla
ut massa tempor, ac dapibus dui viverra.

Donec sed lectus at sem ultrices commodo. Proin a viverra metus, nec scelerisque
odio. Morbi viverra tristique libero vel fringilla. Sed at varius erat, id
consequat nibh. Ut eget leo blandit orci posuere tincidunt ac sed erat. Aenean
metus metus, eleifend ut facilisis a, fringilla ut neque. Nunc hendrerit
cursus eleifend. Pellentesque habitant morbi tristique senectus et netus et
malesuada fames ac turpis egestas. Vivamus enim turpis, pulvinar volutpat
purus nec, lobortis imperdiet diam.  

```{r cs7h}
# code snippet 7.7: two-group simulation
d3 <- rbind(d1, d2)
d3$group <- factor(c(rep(0, nrow(d1)), rep(1, nrow(d2))))
```

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta. Vestibulum hendrerit tempus condimentum. Donec a mollis
sem. Aenean lectus nunc, bibendum ut orci vel, tristique pellentesque arcu.
Vestibulum id laoreet neque. Phasellus at ex velit. Vestibulum scelerisque nulla
ut massa tempor, ac dapibus dui viverra.  

```{r cs7i}
# code snippet 7.8: a mixed model, with two groups
library(nlme)
fm <- lme(Y ~ 1 + time * group, random = ~ 1 + time | id, 
          data = d3)
summary(fm)$tTable
```

```{r fig7k, echo = FALSE, out.width = "100%", fig.asp = .5}
d3$predY <- predict(fm)
ggplot(d3, aes(x = time, y = predY, group = id)) + 
  geom_line(aes(color = group), size = .6, alpha = .2) +  
  geom_smooth(aes(group = NULL), method = "lm", se = FALSE, color = "black") +
  facet_wrap(~group) + coord_cartesian(ylim = c(0, 10)) + theme_classic() +
  guides(color = FALSE)
```

## Power analysis 

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta. Vestibulum hendrerit tempus condimentum. Donec a mollis
sem. Aenean lectus nunc, bibendum ut orci vel, tristique pellentesque arcu.
Vestibulum id laoreet neque. Phasellus at ex velit. Vestibulum scelerisque nulla
ut massa tempor, ac dapibus dui viverra.  

Vivamus enim turpis, pulvinar volutpat purus nec, lobortis imperdiet diam.
Nunc hendrerit cursus eleifend. Pellentesque habitant morbi tristique senectus
et netus et malesuada fames ac turpis egestas. Vivamus enim turpis, pulvinar
volutpat purus nec, lobortis imperdiet diam.

Donec sed lectus at sem ultrices commodo. Proin a viverra
metus, nec scelerisque odio. Morbi viverra tristique libero vel fringilla. Sed
at varius erat, id consequat nibh. Ut eget leo blandit orci posuere tincidunt
ac sed erat. Aenean metus metus, eleifend ut facilisis a, fringilla ut neque.
Nunc hendrerit cursus eleifend. Pellentesque habitant morbi tristique senectus
et netus et malesuada fames ac turpis egestas. Vivamus enim turpis, pulvinar
volutpat purus nec, lobortis imperdiet diam.

## Further reading

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta. Vestibulum hendrerit tempus condimentum. Donec a mollis
sem. Aenean lectus nunc, bibendum ut orci vel, tristique pellentesque arcu.
Vestibulum id laoreet neque. Phasellus at ex velit. Vestibulum scelerisque nulla
ut massa tempor, ac dapibus dui viverra. 

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta. Vestibulum hendrerit tempus condimentum. Donec a mollis
sem. Aenean lectus nunc, bibendum ut orci vel, tristique pellentesque arcu.
Vestibulum id laoreet neque. Phasellus at ex velit. Vestibulum scelerisque nulla
ut massa tempor, ac dapibus dui viverra. 

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam vehicula augue
metus, in tincidunt urna luctus sit amet. Sed ultrices, erat at laoreet semper,
sem tellus hendrerit mi, eget pulvinar massa nisl ac dolor. Nunc ac tellus nec
tortor interdum porta. Vestibulum hendrerit tempus condimentum. Donec a mollis
sem. Aenean lectus nunc, bibendum ut orci vel, tristique pellentesque arcu.
Vestibulum id laoreet neque. Phasellus at ex velit. Vestibulum scelerisque nulla
ut massa tempor, ac dapibus dui viverra. 




